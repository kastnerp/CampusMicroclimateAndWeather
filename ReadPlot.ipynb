{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T18:49:14.495959Z",
     "start_time": "2021-02-12T18:49:14.451960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.7 (default, Apr 15 2020, 05:09:04) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "from hoboreader import HoboReader\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from helper_functions import *\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import csv\n",
    "import unittest\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from setuptools import setup, find_packages\n",
    "from codecs import open\n",
    "from os import path\n",
    "from epw import epw\n",
    "import sys\n",
    "from datetime import datetime, date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from epw import epw\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import math\n",
    "import pandas as pd\n",
    "from hoboreader import HoboReader\n",
    "import sys\n",
    "print(sys.version)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:43:44.448286Z",
     "start_time": "2021-02-11T22:43:34.957934Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "\n",
    "# DL1\tStone Garden - Tjaden Hall\n",
    "# DL2\tPSB Parking Lot\n",
    "# DL3\tOlin Library\n",
    "# DL4\tMilstein Hall Roof\n",
    "# DL5\tGame Farm Road\n",
    "\n",
    "S1 = HoboReader(\"DL1_Stone_Garden_Tjaden_Hall.csv\")\n",
    "S2 = HoboReader(\"DL2_PSB_Parking_Lot.csv\")\n",
    "S3 = HoboReader(\"DL3_Olin_Library.csv\")\n",
    "S4 = HoboReader(\"DL4_Milstein_Hall_Roof.csv\")\n",
    "S5 = HoboReader(\"DL5_Game_Farm_Road.csv\")\n",
    "\n",
    "df1 = S1.get_dataframe()\n",
    "df2 = S2.get_dataframe()\n",
    "df3 = S3.get_dataframe()\n",
    "df4 = S4.get_dataframe()\n",
    "df5 = S5.get_dataframe()\n",
    "\n",
    "# DF5 (GAME FARM ROAD) HAS TO BE SHIFTED BACK BECAUSE IT NATIVELY RECORDS DST, OUR STATIONS DO NOT.\n",
    "# THE OTHER STATIONS ARE NOT SHIFTED (HENCE 0 VALUE FOR PERIODS), JUST THERE FOR SANITY\n",
    "\n",
    "df5 = df5.shift(periods=(-2), fill_value=0)\n",
    "df4 = df4.shift(periods=(0), fill_value=0)\n",
    "df3 = df3.shift(periods=(0), fill_value=0)\n",
    "df2 = df2.shift(periods=(0), fill_value=0)\n",
    "df1 = df1.shift(periods=(0), fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T21:32:52.218026Z",
     "start_time": "2021-02-10T21:32:49.994957Z"
    },
    "code_folding": [
     2,
     4,
     35,
     58,
     107,
     132
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def f(variable_id, period_len, day, resample_len, month, year):\n",
    "\n",
    "    start_time = str(year) + '-' + str(month) + '-' + str(\n",
    "        day) + ' 07:00:00-00:00'\n",
    "    end_time = str(year) + '-' + str(month) + '-' + str(day + period_len -\n",
    "                                                        1) + ' 23:00:00-00:00'\n",
    "\n",
    "    df1_ = df1.loc[start_time:end_time]\n",
    "    df2_ = df2.loc[start_time:end_time]\n",
    "    df3_ = df3.loc[start_time:end_time]\n",
    "    df4_ = df4.loc[start_time:end_time]\n",
    "    df5_ = df5.loc[start_time:end_time]\n",
    "\n",
    "    #Resample subhourly data to 1 hourly graph (OUR STATIONS RECORD IN 10MIN INTERVALS, GFR IN 1HR, RESAMPLE FOR EASY COMPARISON. CAN TURN OFF)\n",
    "    df1_ = df1_.resample(str(resample_len) + 'H').mean()\n",
    "    df2_ = df2_.resample(str(resample_len) + 'H').mean()\n",
    "    df3_ = df3_.resample(str(resample_len) + 'H').mean()\n",
    "    df4_ = df4_.resample(str(resample_len) + 'H').mean()\n",
    "    df5_ = df5_.resample(str(resample_len) + 'H').mean()\n",
    "\n",
    "    # Resize figure\n",
    "    custom_figsize = (30, 15)\n",
    "\n",
    "    # Change lineweights\n",
    "    lineweights = 1.5\n",
    "\n",
    "    variables = [\n",
    "        \"Wind Speed\", \"MRT\", \"Temp\", \"RH\", \"Solar Radiation\", \"Wind Speed\",\n",
    "        \"Gust Speed\", \"Wind Direction\", \"DewPt\"\n",
    "    ]\n",
    "\n",
    "    variable = variables[variable_id]\n",
    "\n",
    "    # Plot both temp and mrt when temp is selected\n",
    "\n",
    "    if variable == \"MRT\" or variable == \"DewPt\" or variable == \"Gust Speed\":\n",
    "        ax = df1_.plot(y=variable, lw=1, figsize=custom_figsize, color='red')\n",
    "        df2_.plot(y=variable,\n",
    "                  lw=1,\n",
    "                  figsize=custom_figsize,\n",
    "                  color='blue',\n",
    "                  ax=ax)\n",
    "        df3_.plot(y=variable,\n",
    "                  lw=1,\n",
    "                  figsize=custom_figsize,\n",
    "                  color='green',\n",
    "                  ax=ax)\n",
    "        df4_.plot(y=variable,\n",
    "                  lw=1,\n",
    "                  figsize=custom_figsize,\n",
    "                  color='aqua',\n",
    "                  ax=ax)\n",
    "        df5_.plot(y=variable,\n",
    "                  lw=3.5,\n",
    "                  figsize=custom_figsize,\n",
    "                  color='black',\n",
    "                  ax=ax)\n",
    "\n",
    "    elif variable == \"Temp\":\n",
    "        # Plot two dataframes into one plot\n",
    "        ax = df1_.plot(y=variable, lw=2, figsize=custom_figsize, color='red')\n",
    "        df2_.plot(y=variable,\n",
    "                  lw=2,\n",
    "                  figsize=custom_figsize,\n",
    "                  color='blue',\n",
    "                  ax=ax)\n",
    "        df3_.plot(y=variable,\n",
    "                  lw=2,\n",
    "                  figsize=custom_figsize,\n",
    "                  color='green',\n",
    "                  ax=ax)\n",
    "        df4_.plot(y=variable,\n",
    "                  lw=2,\n",
    "                  figsize=custom_figsize,\n",
    "                  color='aqua',\n",
    "                  ax=ax)\n",
    "        df5_.plot(y=variable,\n",
    "                  lw=3.5,\n",
    "                  figsize=custom_figsize,\n",
    "                  color='black',\n",
    "                  ax=ax)\n",
    "\n",
    "        ax = df1_.plot(y=\"MRT\",\n",
    "                       lw=1,\n",
    "                       figsize=custom_figsize,\n",
    "                       style=['--'],\n",
    "                       color='red',\n",
    "                       ax=ax)\n",
    "        df2_.plot(y=\"MRT\",\n",
    "                  lw=1,\n",
    "                  figsize=custom_figsize,\n",
    "                  style=['--'],\n",
    "                  color='blue',\n",
    "                  ax=ax)\n",
    "        df3_.plot(y=\"MRT\",\n",
    "                  lw=1,\n",
    "                  figsize=custom_figsize,\n",
    "                  style=['--'],\n",
    "                  color='green',\n",
    "                  ax=ax)\n",
    "        df4_.plot(y=\"MRT\",\n",
    "                  lw=1,\n",
    "                  figsize=custom_figsize,\n",
    "                  style=['--'],\n",
    "                  color='aqua',\n",
    "                  ax=ax)\n",
    "\n",
    "    else:\n",
    "        # Plot two dataframes into one plot\n",
    "        ax = df1_.plot(y=variable, lw=1, figsize=custom_figsize, color='red')\n",
    "        df2_.plot(y=variable,\n",
    "                  lw=1,\n",
    "                  figsize=custom_figsize,\n",
    "                  color='blue',\n",
    "                  ax=ax)\n",
    "        df3_.plot(y=variable,\n",
    "                  lw=1,\n",
    "                  figsize=custom_figsize,\n",
    "                  color='green',\n",
    "                  ax=ax)\n",
    "        df4_.plot(y=variable,\n",
    "                  lw=1,\n",
    "                  figsize=custom_figsize,\n",
    "                  color='aqua',\n",
    "                  ax=ax)\n",
    "        df5_.plot(y=variable,\n",
    "                  lw=2,\n",
    "                  figsize=custom_figsize,\n",
    "                  color='black',\n",
    "                  ax=ax)\n",
    "\n",
    "    # Legend\n",
    "    ax.legend([\n",
    "        \"DL1 - Stone Garden - Tjaden Hall\", \"DL2 - PSB Parking Lot\",\n",
    "        \"DL3 - Olin Library\", \"DL4 - Milstein Hall Roof \",\n",
    "        \"DL5 - Game Farm Road\"\n",
    "    ],\n",
    "              loc='upper left',\n",
    "              frameon=False,\n",
    "              fontsize=20)\n",
    "\n",
    "    # Fix xticks\n",
    "\n",
    "    #years = mdates.YearLocator()  # every year\n",
    "    #months = mdates.MonthLocator()  # every month\n",
    "    #days = mdates.DayLocator()  # every day\n",
    "    #minutes = mdates.MinuteLocator()  # every minute\n",
    "    #days_fmt = mdates.DateFormatter('%d')\n",
    "\n",
    "    # format the ticks\n",
    "    if period_len > 1:\n",
    "        hours = mdates.HourLocator(interval=6)  # every 6 hours\n",
    "        hours_fmt = mdates.DateFormatter('%H:00')\n",
    "        ax.xaxis.set_major_locator(hours)\n",
    "        ax.xaxis.set_major_formatter(hours_fmt)\n",
    "\n",
    "    else:\n",
    "        hours = mdates.HourLocator()  # every 6 hours\n",
    "        hours_fmt = mdates.DateFormatter('%H:00')\n",
    "\n",
    "        ax.xaxis.set_major_locator(hours)\n",
    "        ax.xaxis.set_major_formatter(hours_fmt)\n",
    "\n",
    "    # we dont have minor ticks for now\n",
    "    #ax.xaxis.set_minor_locator(hours)\n",
    "    #ax.tick_params(axis='both', which='minor', labelsize=22)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "    # Labels\n",
    "    plt.ylabel(variable, fontname=\"Consolas\", fontsize=26)\n",
    "    plt.xlabel(\"UTC Time\", fontname=\"Consolas\", fontsize=26)\n",
    "\n",
    "    # Title\n",
    "    ax.set_title(str(\n",
    "        start_time.split(' ')[0] + \" \"\n",
    "        'to'\n",
    "        \" \" + end_time.split(' ')[0] + \" \" + variable),\n",
    "                 fontname=\"Consolas\",\n",
    "                 fontsize=28)\n",
    "\n",
    "    # Save PDF\n",
    "\n",
    "\n",
    "# plot_graph(plt, start_time, variable)\n",
    "\n",
    "# Variable to plot\n",
    "# 1 = \"MRT °C\"\n",
    "# 2 = \"Temp °C\"\n",
    "# 3 = \"RH\"\n",
    "# 4 = \"Solar Radiation\"\n",
    "# 5 = \"Wind Speed\"\n",
    "# 6 = \"Gust Speed\"\n",
    "# 7 = \"Wind Direction\"\n",
    "# 8 = \"DewPt\"\n",
    "\n",
    "interact(f,\n",
    "         variable_id=(1, 8, 1),\n",
    "         period_len=(1, 30, 1),\n",
    "         resample_len=(1, 24, 1),\n",
    "         day=(1, 31, 1),\n",
    "         month=(1, 12, 1),\n",
    "         year=(2019, 2021, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T21:45:19.901642Z",
     "start_time": "2021-02-10T21:45:04.060124Z"
    }
   },
   "outputs": [],
   "source": [
    "#PRINT RESAMPLED DATA (HOURLY) TO A .CSV FOR EPW FILE\n",
    "\n",
    "S1 = HoboReader(\"DL1_Stone_Garden_Tjaden_Hall.csv\")\n",
    "S2 = HoboReader(\"DL2_PSB_Parking_Lot.csv\")\n",
    "S3 = HoboReader(\"DL3_Olin_Library.csv\")\n",
    "S4 = HoboReader(\"DL4_Milstein_Hall_Roof.csv\")\n",
    "\n",
    "df1 = S1.get_dataframe()\n",
    "df2 = S2.get_dataframe()\n",
    "df3 = S3.get_dataframe()\n",
    "df4 = S4.get_dataframe()\n",
    "\n",
    "df1 = df1.resample('H').mean()\n",
    "df2 = df2.resample('H').mean()\n",
    "df3 = df3.resample('H').mean()\n",
    "df4 = df4.resample('H').mean()\n",
    "\n",
    "display(df1)\n",
    "display(df2)\n",
    "display(df3)\n",
    "display(df4)\n",
    "\n",
    "#print(df1)\n",
    "#print(df2)\n",
    "#print(df3)\n",
    "#print(df4)\n",
    "\n",
    "df1.to_csv('DL1_TJADEN_hourly.csv')\n",
    "df2.to_csv('DL2_PSB_hourly.csv')\n",
    "df3.to_csv('DL3_OLIN_hourly.csv')\n",
    "df4.to_csv('DL4_MILSTEIN_hourly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T04:31:46.174416Z",
     "start_time": "2021-02-12T04:31:46.163415Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_1y_data(df, year):\n",
    "    return df[str(year)+'-01-01' :str(year)+'-12-31']\n",
    "#get_1y_data(df5,2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T05:29:09.889723Z",
     "start_time": "2021-02-12T05:28:59.573996Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 µs ± 699 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Reindl split test\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "from hoboreader import HoboReader\n",
    "from gen_reindl import *\n",
    "\n",
    "S2 = HoboReader(\"DL2_PSB_2019_EPW_DATA.csv\")\n",
    "df2 = S2.get_dataframe()\n",
    "\n",
    "# Create date series using date_range() function\n",
    "date_series = pd.date_range('01/01/2019', periods=8760, freq='H')\n",
    "# print(date_series)\n",
    "\n",
    "# altitude M Station (although not necessary for gen_reindl)\n",
    "altitude = 255\n",
    "\n",
    "# lat, lon taken from STATION\n",
    "lat = 42.45062  # north-positive\n",
    "lon = 76.48120  # west-positive for Reindl split (Alstan)\n",
    "\n",
    "# Then the gen_reindl program can be run. -l is longitude (west positive),\n",
    "# -a is latitude (north positive) and -m is the time zone in a multiple of\n",
    "# 15 degrees from the meridian. The command below is for Singapore, and\n",
    "# you note that it is in the wrong time zone. UTC+8 * 15 = -120, despite a\n",
    "# -103.98 longitude.\n",
    "# > gen_reindl -m -120 -l -103.98 -a 1.37 -i input.txt -o output.wea\n",
    "\n",
    "# pos\n",
    "time_zone = 5 * 15  # west-positive\n",
    "\n",
    "#print(\"month, day, time, GHR\\n\")\n",
    "\n",
    "\n",
    "%timeit GenReindl(lat, lon, time_zone).calc_split(4, 22, 8.333333333, 107)\n",
    "\n",
    "\n",
    "def calc_split_df(df):\n",
    "    df['hour'] = df.index.hour\n",
    "    df['day'] = df.index.day\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['DHR'] = 0\n",
    "    df['DNI'] = 0\n",
    "    solar_rad_column = np.argmax(df.columns.get_loc('Solar Radiation'))\n",
    "\n",
    "    i = 0\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        GHR = df.iloc[i, solar_rad_column]\n",
    "        DNI, DHR = GenReindl(lat, lon, time_zone).calc_split(\n",
    "            df.month[i], df.day[i], df.hour[i], GHR)\n",
    "        #print(i,  GHR, DNI, DHR)\n",
    "        dt = datetime(year=df.index.year[i], month=df.index.month[i],\n",
    "                      day=df.index.day[i], hour=df.index.hour[i])\n",
    "        df.loc[dt, 'DHR'] = DHR\n",
    "        df.loc[dt, 'DNI'] = DNI\n",
    "        i += 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:51:56.952692Z",
     "start_time": "2021-02-11T22:51:56.665694Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/8760 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-93ecd5dca62a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#S1 = HoboReader(\"DL1_TJADEN_2019.csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mS2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_split_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-41-b87aa3e9ed51>\u001b[0m in \u001b[0;36mcalc_split_df\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mGHR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolar_rad_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mDNI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDHR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGenReindl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_zone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGHR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m#print(i,  GHR, DNI, DHR)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "#TJADEN HALL STATION\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "#S1 = HoboReader(\"DL1_TJADEN_2019.csv\")\n",
    "df2 = S2.get_dataframe()\n",
    "df2 = calc_split_df(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T14:11:05.722731Z",
     "start_time": "2020-09-13T14:11:05.372615Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# TJADEN HALL STATION\n",
    "\n",
    "#S5 = HoboReader(\"DL1_TJADEN_2019.csv\")\n",
    "#df1 = S1.get_dataframe()\n",
    "\n",
    "# Real file\n",
    "year = 2019\n",
    "ithaca_2019 = epw()\n",
    "# ithaca_2019.headers['LOCATION'][0]='Ithaca_NY'\n",
    "\n",
    "#Design conditions and extreme periods are taken from the Syracuse file\n",
    "\n",
    "ithaca_2019.headers = {\n",
    "    'LOCATION': [\n",
    "        'Ithaca', 'NY', 'USA', 'TMY3', '725190', '42.438934', '-76.492435',\n",
    "        '-5.0', '125.0'\n",
    "    ],\n",
    "    'DESIGN CONDITIONS': [\n",
    "        '1', 'Climate Design Data 2009 ASHRAE Handbook', '', 'Heating', '1',\n",
    "        '-19.3', '-16.2', '-23.6', '0.5', '-18.1', '-20.6', '0.6', '-15.1',\n",
    "        '12.8', '-5.9', '11.9', '-5.9', '3', '90', 'Cooling', '7', '10.8',\n",
    "        '31.6', '22.8', '30', '21.8', '28.5', '21', '24.1', '29.3', '23.1',\n",
    "        '27.9', '22.3', '26.8', '4.4', '260', '22.5', '17.4', '26.9', '21.5',\n",
    "        '16.4', '25.8', '20.7', '15.6', '25.1', '72.9', '29.6', '69.2', '27.9',\n",
    "        '65.9', '26.8', '695', 'Extremes', '10.8', '9.1', '8.2', '27.6',\n",
    "        '-23.6', '33.8', '4', '2', '-26.5', '35.2', '-28.8', '36.3', '-31.1',\n",
    "        '37.4', '-34', '38.9'\n",
    "    ],\n",
    "    'TYPICAL/EXTREME PERIODS': [\n",
    "        '6', 'Summer - Week Nearest Max Temperature For Period', 'Extreme',\n",
    "        '7/27', '8/ 2', 'Summer - Week Nearest Average Temperature For Period',\n",
    "        'Typical', '8/24', '8/30',\n",
    "        'Winter - Week Nearest Min Temperature For Period', 'Extreme', '1/27',\n",
    "        '2/ 2', 'Winter - Week Nearest Average Temperature For Period',\n",
    "        'Typical', '12/22', '12/28',\n",
    "        'Autumn - Week Nearest Average Temperature For Period', 'Typical',\n",
    "        '10/20', '10/26',\n",
    "        'Spring - Week Nearest Average Temperature For Period', 'Typical',\n",
    "        '3/15', '3/21'\n",
    "    ],\n",
    "    'GROUND TEMPERATURES': [\n",
    "        '3', '0.5', '', '', '', '2.44', '4.62', '9.34', '15.56', '21.51',\n",
    "        '25.58', '26.67', '24.44', '19.55', '13.31', '7.40', '3.42', '2', '',\n",
    "        '', '', '5.55', '6.08', '8.78', '13.07', '17.76', '21.58', '23.50',\n",
    "        '23.98', '20.18', '15.85', '11.17', '7.40', '4', '', '', '', '8.79',\n",
    "        '8.41', '9.60', '12.12', '15.30', '18.27', '20.23', '20.66', '19.42',\n",
    "        '16.85', '13.67', '10.73'\n",
    "    ],\n",
    "    'HOLIDAYS/DAYLIGHT SAVINGS': ['No', '0', '0', '0'],\n",
    "    'COMMENTS 1': [''],\n",
    "    'COMMENTS 2': [''],\n",
    "    'DATA PERIODS': ['1', '1', 'Data', 'Sunday', '1/1', '12/31']\n",
    "}\n",
    "\n",
    "#print(ithaca_2019.headers)\n",
    "\n",
    "#variables = [\"Wind Speed\",\"MRT\",\"Temp\",\"RH\",\"Solar Radiation\",\"Wind Speed\",\"Gust Speed\",\"Wind Direction\",\"DewPoint\" ]\n",
    "\n",
    "dt = pd.date_range(datetime(int(year), 1, 1, 0, 00),\n",
    "                   datetime(int(year), 12, 31, 23, 00),\n",
    "                   freq=\"60min\")\n",
    "missing_values = np.array(np.ones(8760) * 999999).astype(int)\n",
    "\n",
    "ithaca_2019.dataframe['Year'] = dt.year.astype(int)\n",
    "ithaca_2019.dataframe['Month'] = dt.month.astype(int)\n",
    "ithaca_2019.dataframe['Day'] = dt.day.astype(int)\n",
    "ithaca_2019.dataframe['Hour'] = dt.hour.astype(int) + 1\n",
    "ithaca_2019.dataframe['Minute'] = dt.minute.astype(int)\n",
    "ithaca_2019.dataframe['Data Source and Uncertainty Flags'] = missing_values\n",
    "\n",
    "# Actual file starts here\n",
    "# .apply(lambda x: ftoc(x), axis=1).values.flatten()\n",
    "ithaca_2019.dataframe['Dry Bulb Temperature'] = df1['Temp'].values.flatten()\n",
    "\n",
    "#     Add this later (ADDED TO DL5_2019 FILE 07.22.2020)\n",
    "# np.array(np.zeros(8760)).astype(int)\n",
    "ithaca_2019.dataframe['Dew Point Temperature'] = df1[\n",
    "    'DewPoint'].values.flatten()\n",
    "\n",
    "ithaca_2019.dataframe['Relative Humidity'] = df1['RH'].values.flatten()\n",
    "\n",
    "# Can use our station pressure for this\n",
    "ithaca_2019.dataframe['Atmospheric Station Pressure'] = df1[\n",
    "    'Pressure'].values.flatten()\n",
    "ithaca_2019.dataframe['Extraterrestrial Horizontal Radiation'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "#\n",
    "ithaca_2019.dataframe['Extraterrestrial Direct Normal Radiation'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "#\n",
    "ithaca_2019.dataframe['Horizontal Infrared Radiation Intensity'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "#\n",
    "ithaca_2019.dataframe['Global Horizontal Radiation'] = df1[\n",
    "    'Solar Radiation'].values.flatten()\n",
    "ithaca_2019.dataframe['Direct Normal Radiation'] = df1['DNI'].values.flatten()\n",
    "ithaca_2019.dataframe['Diffuse Horizontal Radiation'] = df1[\n",
    "    'DHR'].values.flatten()\n",
    "\n",
    "# Do we need this?\n",
    "# https://www.radiance-online.org//pipermail/radiance-general/2013-January/009140.html ?\n",
    "ithaca_2019.dataframe['Global Horizontal Illuminance'] = df1[\n",
    "    'Solar Radiation'].values.flatten() * 179\n",
    "ithaca_2019.dataframe['Direct Normal Illuminance'] = df1['DNI'].values.flatten(\n",
    ") * 179\n",
    "ithaca_2019.dataframe[\n",
    "    'Diffuse Horizontal Illuminance'] = df1['DHR'].values.flatten() * 179\n",
    "\n",
    "ithaca_2019.dataframe['Zenith Luminance'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "\n",
    "ithaca_2019.dataframe['Wind Direction'] = df1['Wind Direction'].values.flatten(\n",
    ").astype(int)\n",
    "ithaca_2019.dataframe['Wind Speed'] = df1['Wind Speed'].values.flatten()\n",
    "\n",
    "#not sure which one to use (skycover)\n",
    "ithaca_2019.dataframe['Total Sky Cover'] = df1['SkyCover'].replace(\n",
    "    ' -', '1.0').astype(float).multiply(10).astype(int).values.flatten()\n",
    "#     This is from Ithaca airport data (NWS, NOAA) (ADDED TO DL1_2019 FILE 08.27.2020)\n",
    "ithaca_2019.dataframe[\n",
    "    'Opaque Sky Cover (used if Horizontal IR Intensity missing)'] = df1[\n",
    "        'SkyCover'].replace(\n",
    "            ' -',\n",
    "            '1.0').astype(float).multiply(10).astype(int).values.flatten()\n",
    "#\n",
    "\n",
    "ithaca_2019.dataframe['Visibility'] = np.array(np.zeros(8760)).astype(int)\n",
    "ithaca_2019.dataframe['Ceiling Height'] = np.array(np.zeros(8760)).astype(int)\n",
    "ithaca_2019.dataframe['Present Weather Observation'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "#\n",
    "ithaca_2019.dataframe['Present Weather Codes'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "ithaca_2019.dataframe['Precipitable Water'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "ithaca_2019.dataframe['Aerosol Optical Depth'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "#\n",
    "ithaca_2019.dataframe['Snow Depth'] = np.array(np.zeros(8760)).astype(int)\n",
    "ithaca_2019.dataframe['Days Since Last Snowfall'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "ithaca_2019.dataframe['Albedo'] = np.array(np.zeros(8760)).astype(int)\n",
    "#\n",
    "\n",
    "# We have precipitation but lets not use it for now\n",
    "ithaca_2019.dataframe['Liquid Precipitation Depth'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "ithaca_2019.dataframe['Liquid Precipitation Quantity'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "display(ithaca_2019.dataframe.loc[8:20])\n",
    "\n",
    "ithaca_2019.write('TjadenHallStation2019.epw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T23:46:19.445195Z",
     "start_time": "2020-11-20T23:43:44.226853Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#S2 = HoboReader(\"DL2_PSB_hourly.csv\")\n",
    "#df2 = S2.get_dataframe()\n",
    "\n",
    "df2 = calc_split_df(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T02:57:22.033292Z",
     "start_time": "2021-02-12T02:57:21.295289Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/8760 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n\u001b[0m\u001b[1m[1] During: typing of argument at <ipython-input-89-f3d62658bea0> (213)\u001b[0m\n\u001b[1m\nFile \"<ipython-input-89-f3d62658bea0>\", line 213:\u001b[0m\n\u001b[1m    def calc_split(self, month, day, time, irrad_glo):\n        <source elided>\n\n\u001b[1m        jday = self.month_and_day_to_julian_day(month, day)\n\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n\nThis error may have been caused by the following argument(s):\n- argument 0: \u001b[1mcannot determine Numba type of <class '__main__.GenReindl2'>\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-1fd51815a3f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#df['DNI'] = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf5_1y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_1y_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2019\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf5_reindl_1y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_split_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf5_1y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-89-f3d62658bea0>\u001b[0m in \u001b[0;36mcalc_split_df\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mGHR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolar_rad_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[0mDNI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDHR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGenReindl2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_zone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGHR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m         \u001b[1;31m#print(i,  GHR, DNI, DHR)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhour\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hobo\\lib\\site-packages\\numba\\dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    399\u001b[0m                 \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m             \u001b[0merror_rewrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'typing'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[1;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hobo\\lib\\site-packages\\numba\\dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[1;34m(e, issue_type)\u001b[0m\n\u001b[0;32m    342\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m                 \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hobo\\lib\\site-packages\\numba\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n\u001b[0m\u001b[1m[1] During: typing of argument at <ipython-input-89-f3d62658bea0> (213)\u001b[0m\n\u001b[1m\nFile \"<ipython-input-89-f3d62658bea0>\", line 213:\u001b[0m\n\u001b[1m    def calc_split(self, month, day, time, irrad_glo):\n        <source elided>\n\n\u001b[1m        jday = self.month_and_day_to_julian_day(month, day)\n\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n\nThis error may have been caused by the following argument(s):\n- argument 0: \u001b[1mcannot determine Numba type of <class '__main__.GenReindl2'>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#S2 = HoboReader(\"DL2_PSB_hourly.csv\")\n",
    "#df2 = S2.get_dataframe()\n",
    "df5 = S5.get_dataframe()\n",
    "\n",
    "#df['DHR'] = 0\n",
    "#df['DNI'] = 0\n",
    "df5_1y = get_1y_data(df5,2019)\n",
    "df5_reindl_1y = calc_split_df(df5_1y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Variables in the epw that we need\n",
    "\n",
    "\n",
    "# From GFR\n",
    "average temperature (F),\n",
    " relative humidity (%), \n",
    "solar radiation (langleys), \n",
    "10 meter wind speed (mph), \n",
    "wind direction (degrees), \n",
    "precipitation (inches)\n",
    "\n",
    "# To EPW\n",
    "\n",
    "average temperature (°C),\n",
    "relative humidity (%), \n",
    "GHI  (Wh/m2), \n",
    "DNI  (Wh/m2), \n",
    "DHI  (Wh/m2), \n",
    "10 meter wind speed (m/s), \n",
    "wind direction (degrees), \n",
    "precipitation (cm or mm)\n",
    "\n",
    "\n",
    "# Make the 2019 file\n",
    "# Make the 2020 file and replace half of the year with the values from 2019\n",
    "\n",
    " df5_2020[start_time:end_time] = df5_2019.loc[start_time:end_time]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T06:24:46.296691Z",
     "start_time": "2021-02-12T06:24:46.250689Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_epw(title, year, hoho_df, reindl_df):\n",
    "\n",
    "    e = epw()\n",
    "\n",
    "    e.headers = {\n",
    "        'LOCATION': [\n",
    "            'Ithaca', 'NY', 'USA', 'TMY3', '725190', '42.43', '-76.49', '-5.0',\n",
    "            '125.0'\n",
    "        ],\n",
    "        'DESIGN CONDITIONS': [],\n",
    "        'TYPICAL/EXTREME PERIODS': [],\n",
    "        'GROUND TEMPERATURES': [],\n",
    "        'HOLIDAYS/DAYLIGHT SAVINGS': [],\n",
    "        'COMMENTS 1': [],\n",
    "        'COMMENTS 2': [],\n",
    "        'DATA PERIODS': []\n",
    "    }\n",
    "\n",
    "    # print(e.headers)\n",
    "\n",
    "    #variables = [\"Wind Speed\",\"MRT\",\"Temp\",\"RH\",\"Solar Radiation\",\"Wind Speed\",\"Gust Speed\",\"Wind Direction\",\"DewPoint\" ]\n",
    "\n",
    "    dt = pd.date_range(datetime(int(year), 1, 1, 0, 00),\n",
    "                       datetime(int(year), 12, 31, 23, 00),\n",
    "                       freq=\"60min\")\n",
    "    missing_values = np.array(np.ones(8760) * 999999).astype(int)\n",
    "\n",
    "    edf = e.dataframe\n",
    "\n",
    "    edf['Year'] = dt.year.astype(int)\n",
    "    edf['Month'] = dt.month.astype(int)\n",
    "    edf['Day'] = dt.day.astype(int)\n",
    "    edf['Hour'] = dt.hour.astype(int) + 1\n",
    "    edf['Minute'] = dt.minute.astype(int)\n",
    "    edf['Data Source and Uncertainty Flags'] = missing_values\n",
    "\n",
    "    # Actual file starts here\n",
    "    # 6\n",
    "    # .apply(lambda x: ftoc(x), axis=1).values.flatten()\n",
    "    edf['Dry Bulb Temperature'] = hoho_df['Temp'].values.flatten()\n",
    "\n",
    "    #     Add this later (ADDED TO DL5_2019 FILE 07.22.2020)\n",
    "    # missing_values\n",
    "    edf['Dew Point Temperature'] = hoho_df['DewPt'].values.flatten()\n",
    "\n",
    "    edf['Relative Humidity'] = hoho_df['RH'].values.flatten()\n",
    "\n",
    "    # Added NREL pressure 2020-08-21\n",
    "    if 'Pressure' in hoho_df:    \n",
    "        edf['Atmospheric Station Pressure'] = hoho_df['Pressure'].values.flatten()\n",
    "    else: \n",
    "        edf['Atmospheric Station Pressure'] = missing_values\n",
    "        \n",
    "        \n",
    "    edf['Extraterrestrial Horizontal Radiation'] = missing_values\n",
    "    #\n",
    "    edf['Extraterrestrial Direct Normal Radiation'] = missing_values\n",
    "    #\n",
    "    edf['Horizontal Infrared Radiation Intensity'] = missing_values\n",
    "    #\n",
    "    edf['Global Horizontal Radiation'] = hoho_df[\n",
    "        'Solar Radiation'].values.flatten()\n",
    "    edf['Direct Normal Radiation'] = reindl_df['DNI'].values.flatten()\n",
    "    edf['Diffuse Horizontal Radiation'] = reindl_df['DHR'].values.flatten()\n",
    "\n",
    "    # Do we need this?\n",
    "    # https://www.radiance-online.org//pipermail/radiance-general/2013-January/009140.html ?\n",
    "    edf['Global Horizontal Illuminance'] = hoho_df['Solar Radiation'].values.flatten() * \\\n",
    "        179\n",
    "    edf['Direct Normal Illuminance'] = reindl_df['DNI'].values.flatten() * 179\n",
    "    edf['Diffuse Horizontal Illuminance'] = reindl_df['DHR'].values.flatten(\n",
    "    ) * 179\n",
    "\n",
    "    edf['Zenith Luminance'] = missing_values\n",
    "\n",
    "    edf['Wind Direction'] = hoho_df['Wind Direction'].values.flatten().astype(\n",
    "        int)\n",
    "    edf['Wind Speed'] = hoho_df['Wind Speed'].values.flatten()\n",
    "\n",
    "    if 'SkyCover' in hoho_df:\n",
    "    \n",
    "    # not sure which one to use (skycover)\n",
    "        edf['Total Sky Cover'] = hoho_df['SkyCover'].replace(\n",
    "        ' -', '1.0').astype(float).multiply(10).astype(int).values.flatten()\n",
    "    #     This is from Ithaca airport data (NWS, NOAA) (ADDED TO DL5_2019 FILE 07.22.2020)\n",
    "    #  (used if Horizontal IR Intensity missing)\n",
    "        edf['Opaque Sky Cover'] = hoho_df['SkyCover'].replace(\n",
    "        ' -', '1.0').astype(float).multiply(10).astype(int).values.flatten()\n",
    "    else:\n",
    "        edf['Total Sky Cover'] = missing_values\n",
    "        edf['Opaque Sky Cover'] = missing_values\n",
    "            \n",
    "    #\n",
    "\n",
    "    edf['Visibility'] = missing_values\n",
    "    edf['Ceiling Height'] = missing_values\n",
    "    edf['Present Weather Observation'] = missing_values\n",
    "    #\n",
    "    edf['Present Weather Codes'] = missing_values\n",
    "    edf['Precipitable Water'] = missing_values\n",
    "    edf['Aerosol Optical Depth'] = missing_values\n",
    "    #\n",
    "    edf['Snow Depth'] = missing_values\n",
    "    edf['Days Since Last Snowfall'] = missing_values\n",
    "    edf['Albedo'] = missing_values\n",
    "    #\n",
    "\n",
    "    # We have precipitation but lets not use it for now\n",
    "    edf['Liquid Precipitation Depth'] = missing_values\n",
    "    edf['Liquid Precipitation Quantity'] = missing_values\n",
    "\n",
    "    #pd.options.display.max_columns = None\n",
    "    #display(edf.loc[8:15])\n",
    "    \n",
    "    filename = str(title) + \"_\"+  str(year) + '.epw'\n",
    "\n",
    "    e.write(filename)\n",
    "    \n",
    "    with open(filename,'r') as file:\n",
    "        filedata = file.read()\n",
    "        filedata = filedata.replace('.0,',',')\n",
    "    with open(filename,'w') as file:\n",
    "        file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T05:20:48.200489Z",
     "start_time": "2021-02-12T05:20:48.015474Z"
    },
    "code_folding": [
     51
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-1f1208a1e30f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# Real file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mdf5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_1y_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2019\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# e.headers['LOCATION'][0]='Ithaca_NY'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df5' is not defined"
     ]
    }
   ],
   "source": [
    "# GAME FARM ROAD_ITHACA STATION\n",
    "\n",
    "#S5 = HoboReader(\"DL5_Game_Farm_Road_2019.csv\")\n",
    "#hoho_df = S5.get_dataframe()\n",
    "\n",
    "# There are about 35 variables in the core weather data. However, not all of them are used by EnergyPlus. Actually, despite of date and time columns, only 13 columns are used:\n",
    "# dry bulb temperature\n",
    "# dew point temperature\n",
    "# relative humidity\n",
    "# atmospheric pressure\n",
    "# horizontal infrared radiation intensity from sky\n",
    "# direct normal radiation\n",
    "# diffuse horizontal radiation\n",
    "# wind direction\n",
    "# wind speed\n",
    "# present weather observation\n",
    "# present weather codes\n",
    "# snow depth\n",
    "# liquid precipitation depth\n",
    "\n",
    "# https://www.radiance-online.org/pipermail/radiance-general/2015-April/010841.html\n",
    "\n",
    "# Daniel,\n",
    "\n",
    "# You should be able to generate the .wea file from diffuse horizontal\n",
    "# radiation and direct normal radiation values. The structure of the lines\n",
    "# after the heading in .wea file is:\n",
    "\n",
    "# month day hour directNormalRadiation diffuseHorizontalRadiation\n",
    "\n",
    "# Load NREL 2019 and take atmospheric pressure from there\n",
    "year = 2019\n",
    "nrel_2019 = Path.cwd() / Path(\"nrel_data/1162143_42.45_-76.50_2019.csv\")\n",
    "# print(nrel_2019)\n",
    "nrel_2019_df = pd.read_csv(nrel_2019)\n",
    "#df.columns = df.index[0]\n",
    "nrel_2019_df.columns = nrel_2019_df.loc[nrel_2019_df.index[1]]\n",
    "nrel_2019_df = nrel_2019_df.drop(nrel_2019_df.index[0])\n",
    "nrel_2019_df = nrel_2019_df.drop(nrel_2019_df.index[0])\n",
    "\n",
    "nrel_2019_pressure = nrel_2019_df['Pressure'].astype(int) * 100\n",
    "\n",
    "# Real file\n",
    "\n",
    "df5 = get_1y_data(df5, 2019)\n",
    "\n",
    "# e.headers['LOCATION'][0]='Ithaca_NY'\n",
    "\n",
    "# Design conditions and extreme periods are taken from the Syracuse file\n",
    "\n",
    "make_epw(\"GameFarmRoad\", \"2019\",df5, df5_reindl_1y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T06:25:42.435717Z",
     "start_time": "2021-02-12T06:24:49.637738Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkastner\\Anaconda3\\envs\\hobo\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\pkastner\\Anaconda3\\envs\\hobo\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\pkastner\\Anaconda3\\envs\\hobo\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\pkastner\\Anaconda3\\envs\\hobo\\lib\\site-packages\\ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\pkastner\\Anaconda3\\envs\\hobo\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\pkastner\\Anaconda3\\envs\\hobo\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  0%|                                                                                         | 0/1979 [00:00<?, ?it/s]C:\\Users\\pkastner\\Anaconda3\\envs\\hobo\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1979/1979 [00:48<00:00, 41.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Milstein Hall Roof\n",
    "year = 2019\n",
    "\n",
    "S4 = HoboReader(\"DL4_Milstein_Hall_Roof.csv\")\n",
    "df4 = S4.get_dataframe()\n",
    "df4 = df4.resample('H').mean()\n",
    "\n",
    "df4_1y = get_1y_data(df4,2019)\n",
    "df4_1y.index = df4_1y.index .tz_convert(None)\n",
    "df4_split = calc_split_df(df4_1y)\n",
    "\n",
    "ix = pd.date_range(datetime(int(year), 1, 1, 0, 00),\n",
    "                       datetime(int(year), 12, 31, 23, 00),\n",
    "                       freq=\"60min\")\n",
    "df4_1y_re= df4_1y.reindex(ix).fillna(999)\n",
    "df4_split_re= df4_split.reindex(ix).fillna(999)\n",
    "make_epw(\"DL4_Milstein\", year, df4_1y_re, df4_split_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T06:14:57.925854Z",
     "start_time": "2021-02-12T06:14:57.122852Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T18:49:07.120598Z",
     "start_time": "2021-02-12T18:48:52.996474Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8760/8760 [00:14<00:00, 622.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "[6918, 6919, 6920, 6921, 6922, 6923, 6951, 6952, 6953, 6954, 6955, 6956, 6957, 6958, 6959, 6960, 6961, 6962, 6963, 6964, 6965, 6966, 6967, 6968, 6969, 6970, 6971, 6972, 6973, 6974, 6975, 6976, 7036, 7037, 7061, 7062, 7063, 7064, 7065, 7066, 7067, 7177, 7178, 7179, 7180, 7181, 7182, 7183, 7184, 7185, 7186, 7282, 7283, 7284, 7285, 7286, 7300, 7301, 7302, 7303, 7304, 7305, 7306, 7307, 7308, 7309, 7310, 7496, 7584, 7585, 7586, 7619, 7620, 7621, 7622, 7699, 7700, 7795, 7814, 7845, 7846, 7898, 7899, 7900, 7901, 7986, 7987, 7988, 8057, 8058, 8059, 8121, 8122, 8123, 8124, 8125, 8126, 8196, 8197, 8198, 8199, 8200, 8201, 8202, 8203, 8204, 8205, 8206, 8207, 8208, 8209, 8210, 8211, 8212, 8228, 8229, 8304, 8305, 8306, 8307, 8308, 8317, 8352, 8353, 8354, 8355, 8356, 8357, 8358, 8359, 8360, 8361, 8362, 8363, 8364, 8449, 8450, 8451, 8452, 8453, 8454, 8455, 8456, 8457, 8458, 8459, 8460, 8461, 8510, 8511, 8512, 8513, 8550, 8551, 8632, 8633, 8634, 8635, 8636, 8637, 8638, 8639, 8640, 8641, 8642, 8643, 8644, 8645, 8646, 8647, 8648, 8649, 8650, 8688, 8689, 8708, 8709, 8710, 8721, 8722, 8723, 8724, 8725, 8726, 8737, 8738, 8739, 8740, 8758, 8759]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# h = find_hours_w_constant_wind_dirs(10, 8, wind_df)\n",
    "# h will give you all hours of the year for which the following 8 hours are within +-10° of wind direction in either direction\n",
    "\n",
    "\n",
    "df = a.dataframe.loc[:,['Wind Direction']]\n",
    "s = df['Wind Direction']\n",
    "\n",
    "\n",
    "h = find_hours_w_constant_wind_dirs(10, 8 , s)\n",
    "print(len(h))\n",
    "print(h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T18:44:38.641558Z",
     "start_time": "2021-02-12T18:44:38.508561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Wind Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>1.226380</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>1.227870</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>2.171869</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>2.004974</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>3.396014</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Wind Speed  Wind Direction\n",
       "0     999.000000             999\n",
       "1     999.000000             999\n",
       "2     999.000000             999\n",
       "3     999.000000             999\n",
       "4     999.000000             999\n",
       "...          ...             ...\n",
       "8755    1.226380             194\n",
       "8756    1.227870             198\n",
       "8757    2.171869             225\n",
       "8758    2.004974             226\n",
       "8759    3.396014             228\n",
       "\n",
       "[8760 rows x 2 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = epw()\n",
    "a.read(\"DL4_Milstein_2019.epw\")\n",
    "day = 31\n",
    "month = 12\n",
    "year = 2019\n",
    "hour_f = to_hour_of_year(0, day, month, year)\n",
    "hour_t = to_hour_of_year(23, day, month,year)\n",
    "#a.dataframe.loc[hour_f-48:hour_t,['Wind Speed', 'Wind Direction']]\n",
    "a.dataframe.loc[:,['Wind Speed', 'Wind Direction']]\n",
    "#pd.set_option('display.max_rows', 100)\n",
    "#display(a.dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T17:29:54.768781Z",
     "start_time": "2020-11-21T17:29:54.682985Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PSB Parking Lot\n",
    "\n",
    "\n",
    "S2 = HoboReader(\"DL2_PSB_20202021_EPW.csv\")\n",
    "df2 = S2.get_dataframe()\n",
    "\n",
    "\n",
    "df2 = calc_split_df(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T23:50:20.366889Z",
     "start_time": "2020-11-20T23:50:19.973940Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.to_csv(\"PSB2020_edit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T23:59:55.877961Z",
     "start_time": "2020-11-20T23:59:55.804646Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"PSB2020_edit_done.csv\")\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T23:47:24.981512Z",
     "start_time": "2020-11-20T23:47:24.113738Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PSB_ITHACA STATION\n",
    "\n",
    "#S2 = HoboReader(\"DL2_PSB_2019_EPW_DATA.csv\")\n",
    "#df2 = S2.get_dataframe()\n",
    "\n",
    "# Template\n",
    "\n",
    "template = epw()\n",
    "template.read('USA_NY_Ithaca_Template.epw')\n",
    "template.dataframe.columns\n",
    "\n",
    "# Real file\n",
    "\n",
    "PSB_2019 = epw()\n",
    "# PSB_2019.headers['LOCATION'][0]='Ithaca_NY'\n",
    "\n",
    "PSB_2019.headers = {\n",
    "    'LOCATION': [\n",
    "        'PSB Parking Lot, Cornell University', 'NY', 'USA', 'TMY3', '725190',\n",
    "        '42.450620', '-76.481201', '-5.0', '255.0'\n",
    "    ],\n",
    "    'DESIGN CONDITIONS': [\n",
    "        '1', 'Climate Design Data 2009 ASHRAE Handbook', '', 'Heating', '1',\n",
    "        '-19.3', '-16.2', '-23.6', '0.5', '-18.1', '-20.6', '0.6', '-15.1',\n",
    "        '12.8', '-5.9', '11.9', '-5.9', '3', '90', 'Cooling', '7', '10.8',\n",
    "        '31.6', '22.8', '30', '21.8', '28.5', '21', '24.1', '29.3', '23.1',\n",
    "        '27.9', '22.3', '26.8', '4.4', '260', '22.5', '17.4', '26.9', '21.5',\n",
    "        '16.4', '25.8', '20.7', '15.6', '25.1', '72.9', '29.6', '69.2', '27.9',\n",
    "        '65.9', '26.8', '695', 'Extremes', '10.8', '9.1', '8.2', '27.6',\n",
    "        '-23.6', '33.8', '4', '2', '-26.5', '35.2', '-28.8', '36.3', '-31.1',\n",
    "        '37.4', '-34', '38.9'\n",
    "    ],\n",
    "    'TYPICAL/EXTREME PERIODS': [\n",
    "        '6', 'Summer - Week Nearest Max Temperature For Period', 'Extreme',\n",
    "        '7/27', '8/ 2', 'Summer - Week Nearest Average Temperature For Period',\n",
    "        'Typical', '8/24', '8/30',\n",
    "        'Winter - Week Nearest Min Temperature For Period', 'Extreme', '1/27',\n",
    "        '2/ 2', 'Winter - Week Nearest Average Temperature For Period',\n",
    "        'Typical', '12/22', '12/28',\n",
    "        'Autumn - Week Nearest Average Temperature For Period', 'Typical',\n",
    "        '10/20', '10/26',\n",
    "        'Spring - Week Nearest Average Temperature For Period', 'Typical',\n",
    "        '3/15', '3/21'\n",
    "    ],\n",
    "    'GROUND TEMPERATURES': [\n",
    "        '3', '0.5', '', '', '', '2.44', '4.62', '9.34', '15.56', '21.51',\n",
    "        '25.58', '26.67', '24.44', '19.55', '13.31', '7.40', '3.42', '2', '',\n",
    "        '', '', '5.55', '6.08', '8.78', '13.07', '17.76', '21.58', '23.50',\n",
    "        '23.98', '20.18', '15.85', '11.17', '7.40', '4', '', '', '', '8.79',\n",
    "        '8.41', '9.60', '12.12', '15.30', '18.27', '20.23', '20.66', '19.42',\n",
    "        '16.85', '13.67', '10.73'\n",
    "    ],\n",
    "    'GROUND TEMPERATURES': [\n",
    "        '3', '0.5', '', '', '', '2.44', '4.62', '9.34', '15.56', '21.51',\n",
    "        '25.58', '26.67', '24.44', '19.55', '13.31', '7.40', '3.42', '2', '',\n",
    "        '', '', '5.55', '6.08', '8.78', '13.07', '17.76', '21.58', '23.50',\n",
    "        '23.98', '20.18', '15.85', '11.17', '7.40', '4', '', '', '', '8.79',\n",
    "        '8.41', '9.60', '12.12', '15.30', '18.27', '20.23', '20.66', '19.42',\n",
    "        '16.85', '13.67', '10.73'\n",
    "    ],\n",
    "    'HOLIDAYS/DAYLIGHT SAVINGS': ['No', '0', '0', '0'],\n",
    "    'COMMENTS 1': [''],\n",
    "    'COMMENTS 2': [''],\n",
    "    'DATA PERIODS': ['1', '1', 'Data', 'Sunday', '1/1', '12/31']\n",
    "}\n",
    "\n",
    "#print(PSB_2019.headers)\n",
    "\n",
    "#variables = [\"Wind Speed\",\"MRT\",\"Temp\",\"RH\",\"Solar Radiation\",\"Wind Speed\",\"Gust Speed\",\"Wind Direction\",\"DewPoint\" ]\n",
    "\n",
    "dt = pd.date_range(datetime(int(year), 1, 1, 0, 00),\n",
    "                   datetime(int(year), 12, 31, 23, 00),\n",
    "                   freq=\"60min\")\n",
    "missing_values = np.array(np.ones(8760) * 999999).astype(int)\n",
    "\n",
    "PSB_2019.dataframe['Year'] = dt.year.astype(int)\n",
    "PSB_2019.dataframe['Month'] = dt.month.astype(int)\n",
    "PSB_2019.dataframe['Day'] = dt.day.astype(int)\n",
    "PSB_2019.dataframe['Hour'] = dt.hour.astype(int) + 1\n",
    "PSB_2019.dataframe['Minute'] = dt.minute.astype(int)\n",
    "PSB_2019.dataframe['Data Source and Uncertainty Flags'] = missing_values\n",
    "\n",
    "# Actual file starts here\n",
    "# 6\n",
    "# .apply(lambda x: ftoc(x), axis=1).values.flatten()\n",
    "PSB_2019.dataframe['Dry Bulb Temperature'] = df2['Temp'].values.flatten()\n",
    "# np.array(np.zeros(8760)).astype(int)\n",
    "PSB_2019.dataframe['Dew Point Temperature'] = df2['DewPt'].values.flatten()\n",
    "\n",
    "PSB_2019.dataframe['Relative Humidity'] = df2['RH'].values.flatten()\n",
    "\n",
    "# Added NREL pressure 2020-08-21\n",
    "PSB_2019.dataframe[\n",
    "    'Atmospheric Station Pressure'] = nrel_2019_pressure.values.flatten()\n",
    "PSB_2019.dataframe['Extraterrestrial Horizontal Radiation'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "#\n",
    "PSB_2019.dataframe['Extraterrestrial Direct Normal Radiation'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "#\n",
    "PSB_2019.dataframe['Horizontal Infrared Radiation Intensity'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "#\n",
    "PSB_2019.dataframe['Global Horizontal Radiation'] = df2[\n",
    "    'Solar Radiation'].values.flatten()\n",
    "PSB_2019.dataframe['Direct Normal Radiation'] = df2['DNI'].values.flatten()\n",
    "PSB_2019.dataframe['Diffuse Horizontal Radiation'] = df2['DHR'].values.flatten(\n",
    ")\n",
    "\n",
    "# Do we need this?\n",
    "PSB_2019.dataframe['Global Horizontal Illuminance'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "PSB_2019.dataframe['Direct Normal Illuminance'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "PSB_2019.dataframe['Diffuse Horizontal Illuminance'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "PSB_2019.dataframe['Zenith Luminance'] = np.array(np.zeros(8760)).astype(int)\n",
    "\n",
    "PSB_2019.dataframe['Wind Direction'] = df2['Wind Direction'].values.flatten(\n",
    ").astype(int)\n",
    "PSB_2019.dataframe['Wind Speed'] = df2['Wind Speed'].values.flatten()\n",
    "\n",
    "#not sure which one to use (skycover)\n",
    "PSB_2019.dataframe['Total Sky Cover'] = df2['SkyCover'].replace(\n",
    "    ' -', '1.0').astype(float).multiply(10).astype(int).values.flatten()\n",
    "#     This is from Ithaca airport data (NWS, NOAA) (ADDED TO DL5_2019 FILE 07.22.2020)\n",
    "PSB_2019.dataframe[\n",
    "    'Opaque Sky Cover (used if Horizontal IR Intensity missing)'] = df2[\n",
    "        'SkyCover'].replace(\n",
    "            ' -',\n",
    "            '1.0').astype(float).multiply(10).astype(int).values.flatten()\n",
    "#\n",
    "\n",
    "PSB_2019.dataframe['Visibility'] = np.array(np.zeros(8760)).astype(int)\n",
    "PSB_2019.dataframe['Ceiling Height'] = np.array(np.zeros(8760)).astype(int)\n",
    "PSB_2019.dataframe['Present Weather Observation'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "#\n",
    "PSB_2019.dataframe['Present Weather Codes'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "PSB_2019.dataframe['Precipitable Water'] = np.array(np.zeros(8760)).astype(int)\n",
    "PSB_2019.dataframe['Aerosol Optical Depth'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "#\n",
    "PSB_2019.dataframe['Snow Depth'] = np.array(np.zeros(8760)).astype(int)\n",
    "PSB_2019.dataframe['Days Since Last Snowfall'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "PSB_2019.dataframe['Albedo'] = np.array(np.zeros(8760)).astype(int)\n",
    "#\n",
    "\n",
    "# We have precipitation but lets not use it for now\n",
    "PSB_2019.dataframe['Liquid Precipitation Depth'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "PSB_2019.dataframe['Liquid Precipitation Quantity'] = np.array(\n",
    "    np.zeros(8760)).astype(int)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "display(PSB_2019.dataframe.loc[8:20])\n",
    "\n",
    "PSB_2019.write('PSBLot_20192020.epw')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hobo]",
   "language": "python",
   "name": "conda-env-hobo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
